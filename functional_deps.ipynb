{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions (Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "import random\n",
    "import string\n",
    "\n",
    "def compute_closure(attributes, fds) -> set:\n",
    "    \"\"\"\n",
    "    Compute the closure of a set of attributes under a set of functional dependencies\n",
    "    ---------------------------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    closure = set(attributes)\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for fd in fds:\n",
    "            if fd[0].issubset(closure) and not fd[1].issubset(closure):\n",
    "                closure.update(fd[1])\n",
    "                changed = True\n",
    "    return closure\n",
    "\n",
    "def compute_all_closures(attributes, fds) -> dict:\n",
    "    \"\"\"\n",
    "    Compute the closure of all possible subsets of a set of attributes\n",
    "    ------------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    all_closures = {}\n",
    "    for r in range(1, len(attributes) + 1):\n",
    "        for subset in combinations(attributes, r):\n",
    "            subset_closure = compute_closure(set(subset), fds)\n",
    "            all_closures[tuple(subset)] = subset_closure\n",
    "    return all_closures\n",
    "\n",
    "def compute_candidate_keys(closure_set, attributes) -> list:\n",
    "    \"\"\"\n",
    "    Compute the candidate keys of a set of attributes\n",
    "    -------------------------------------------------\n",
    "    closure_set: a dictionary of all closures\n",
    "    attributes: a set of attributes\n",
    "    \"\"\"\n",
    "    super_keys = []\n",
    "    for i in closure_set:\n",
    "        if set(closure_set[i]) == set(attributes):\n",
    "            super_keys.append(i)\n",
    "    candidate_keys = []\n",
    "    for j in super_keys:\n",
    "        flag = False\n",
    "        for i in super_keys:\n",
    "            if set(i) != set(j):\n",
    "                if set(i).issubset(set(j)):\n",
    "                    flag = True\n",
    "        if flag == False:\n",
    "            candidate_keys.append(j)\n",
    "    return candidate_keys\n",
    "\n",
    "def find_prime_attributes(candidate_keys) -> set:\n",
    "    \"\"\"\n",
    "    Find the prime attributes of a set of candidate keys\n",
    "    ----------------------------------------------------\n",
    "    candidate_keys: a list of candidate keys\n",
    "    \"\"\"\n",
    "    prime_attributes = set()\n",
    "    for key in candidate_keys:\n",
    "        prime_attributes.update(key)\n",
    "    return prime_attributes\n",
    "\n",
    "def compute_single_covers(attributes, fds) -> dict:\n",
    "    \"\"\"\n",
    "    Compute the closure of each attribute in a set of attributes\n",
    "    ------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    all_closures = {}\n",
    "    for a in attributes:\n",
    "        subset_closure = compute_closure(a, fds)\n",
    "        all_closures[a] = subset_closure\n",
    "    return all_closures\n",
    "\n",
    "def project_dependency(fds, R_hat) -> list:\n",
    "    \"\"\"\n",
    "    Project a set of functional dependencies on a set of attributes\n",
    "    ---------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    R_hat: a set of attributes\n",
    "    \"\"\"\n",
    "    fds_hat = []\n",
    "    for fd in fds:\n",
    "        if fd[0].issubset(R_hat):\n",
    "            y = fd[1].intersection(R_hat)\n",
    "            if len(y)>0:\n",
    "                fds_hat.append((fd[0],y))\n",
    "    for fd in fds_hat:\n",
    "        if fd[0] == fd[1]:\n",
    "            fds_hat.remove(fd)\n",
    "    return fds_hat\n",
    "\n",
    "## Minimal cover computation\n",
    "\n",
    "def decompose_fds(fds) -> list:\n",
    "    \"\"\"Decompose each FD so that the RHS contains only one attribute.\n",
    "    For example, the FD {A} -> {B, C} will be decomposed into {A} -> {B} and {A} -> {C}.\n",
    "    ------------------------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    decomposed_fds = []\n",
    "    for lhs, rhs in fds:\n",
    "        for attr in rhs:\n",
    "            decomposed_fds.append((lhs, {attr}))\n",
    "    return decomposed_fds\n",
    "\n",
    "def remove_trivial_dependencies(fds) -> list:\n",
    "    \"\"\"Remove trivial FDs of the form A -> A.\n",
    "    -----------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    return [(lhs, rhs) for lhs, rhs in fds if lhs != rhs]\n",
    "\n",
    "def remove_redundant_dependencies(fds) -> list:\n",
    "    \"\"\"Remove redundant FDs by checking if we can infer a FD from others.\n",
    "    ---------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    fds_ = fds.copy()\n",
    "    len_fds_1 = len(fds_)\n",
    "    len_fds_2 = 0\n",
    "    while len_fds_1>len_fds_2:\n",
    "        len_fds_1 = len(fds_)\n",
    "        for i, (lhs, rhs) in enumerate(fds_):\n",
    "            remaining_fds = fds_[:i] + fds_[i+1:]\n",
    "            closure_lhs = compute_closure(lhs, remaining_fds)\n",
    "            if rhs.issubset(closure_lhs):\n",
    "                fds_.remove((lhs, rhs))\n",
    "        len_fds_2 = len(fds_)\n",
    "    return fds_\n",
    "\n",
    "def merge_fds(fds) -> list:\n",
    "    \"\"\"Merge FDs with the same LHS back together.\n",
    "    --------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    merged_fds = {}\n",
    "    for lhs, rhs in fds:\n",
    "        lhs = tuple(lhs)\n",
    "        if lhs in merged_fds:\n",
    "            merged_fds[lhs].update(rhs)\n",
    "        else:\n",
    "            merged_fds[lhs] = set(rhs)\n",
    "    \n",
    "    return [(set(lhs), rhs) for lhs, rhs in merged_fds.items()]\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"Generate all non-empty proper subsets of a set.\"\"\"\n",
    "    s = list(iterable)\n",
    "    combs = [[i for i in combinations(s, r)] for r in range(1, len(s)+1)]\n",
    "    return [x for xs in combs for x in xs]\n",
    "\n",
    "def remove_superfluous_lhs(fds, p):\n",
    "    \"\"\"\n",
    "    Simplify the LHS by checking if any proper subset of the LHS can imply the RHS.\n",
    "    --------------------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    p: probability of choosing a random minimal lhs\n",
    "    \"\"\"\n",
    "    minimal_fds = []\n",
    "    for lhs, rhs in fds:\n",
    "        minimal_lhs = lhs\n",
    "        min_sub = 10000\n",
    "        minimals = []\n",
    "        for subset in powerset(lhs):\n",
    "            if len(subset) <= min_sub:\n",
    "                if rhs.issubset(compute_closure(set(subset), fds)):\n",
    "                    minimal_lhs = set(subset)\n",
    "                    min_sub = len(subset)\n",
    "                    minimals.append(minimal_lhs)\n",
    "        if len(minimals)>1 and random.randint(0, 10) <= p*10:\n",
    "            minimal_lhs = set(random.choice(minimals))\n",
    "        else:\n",
    "            minimal_lhs = minimals[0]\n",
    "            \n",
    "        minimal_fds.append((minimal_lhs, rhs))\n",
    "    return minimal_fds\n",
    "\n",
    "def minimal_cover(fds, p = 0.5) -> list:\n",
    "    \"\"\"Find the minimal cover of a set of FDs.\n",
    "    -----------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    # Step 1: Decompose the RHS\n",
    "    decomposed_fds = decompose_fds(fds)\n",
    "\n",
    "    # Step 2: Simplify LHS\n",
    "    simplified_fds = remove_superfluous_lhs(decomposed_fds, p)\n",
    "\n",
    "    # Step 3: Remove trivial dependencies (A -> A)\n",
    "    simplified_fds = remove_trivial_dependencies(simplified_fds)\n",
    "\n",
    "    # Step 4: Remove redundant FDs\n",
    "    simplified_fds = remove_redundant_dependencies(simplified_fds)\n",
    "    \n",
    "    # Step 5: Recollect FDs with the same LHS\n",
    "    minimal_fds = merge_fds(simplified_fds)\n",
    "    \n",
    "    return minimal_fds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = {'A', 'B', 'C', 'D', 'E'}\n",
    "fds = [\n",
    "    ({'A', 'B'}, {'C'}),\n",
    "    ({'C'}, {'A'}),\n",
    "    ({'B', 'C', 'D'}, {'A', 'B'}),\n",
    "    ({'B', 'C', 'D'}, {'D', 'E'}),\n",
    "    ({'C', 'D'}, {'D', 'E'}),\n",
    "    ({'E'}, {'D', 'E'})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_closures = compute_all_closures(attributes, fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A'}+ = {'A'}\n",
      "{'C'}+ = {'A', 'C', 'B'}\n",
      "{'D'}+ = {'D'}\n",
      "{'B'}+ = {'B'}\n",
      "{'A', 'C'}+ = {'A', 'C', 'B'}\n",
      "{'A', 'D'}+ = {'A', 'D'}\n",
      "{'A', 'B'}+ = {'A', 'B'}\n",
      "{'C', 'D'}+ = {'A', 'C', 'D', 'B'}\n",
      "{'C', 'B'}+ = {'A', 'C', 'B'}\n",
      "{'D', 'B'}+ = {'D', 'B'}\n",
      "{'A', 'C', 'D'}+ = {'C', 'A', 'D', 'B'}\n",
      "{'A', 'C', 'B'}+ = {'A', 'C', 'B'}\n",
      "{'A', 'D', 'B'}+ = {'A', 'D', 'B'}\n",
      "{'C', 'D', 'B'}+ = {'A', 'C', 'D', 'B'}\n",
      "{'A', 'C', 'D', 'B'}+ = {'A', 'C', 'D', 'B'}\n"
     ]
    }
   ],
   "source": [
    "for k in all_closures:\n",
    "    print('{k}+ = {v}'.format(k=set(k), v=all_closures[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'D')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_candidate_keys(all_closures, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'D'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_prime_attributes(compute_candidate_keys(all_closures, attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C'} -> {'A', 'B'}\n"
     ]
    }
   ],
   "source": [
    "minimal_fds = minimal_cover(fds, p = 0.5)\n",
    "for lhs, rhs in minimal_fds:\n",
    "    print(f\"{lhs} -> {rhs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency projection example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'C'}, {'A', 'B'})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat = {'A', 'B', 'C'}\n",
    "project_dependency(fds, R_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random FDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attribute_names(n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Build n attribute names with UPPER and lower case letters:\n",
    "    \"\"\"\n",
    "    upper = list(string.ascii_uppercase)   # 26\n",
    "    lower = list(string.ascii_lowercase)   # 26\n",
    "\n",
    "    base = []   \n",
    "    for u in upper:\n",
    "        base.append(u)\n",
    "    for l in lower:\n",
    "        base.append(l)\n",
    "    names = []\n",
    "    k = 0\n",
    "    while len(names) < n:\n",
    "        for idx, sym in enumerate(base):\n",
    "            if len(names) >= n:\n",
    "                break\n",
    "            suffix = \"\" if k == 0 else str(k)\n",
    "            names.append(f\"{sym}{suffix}\")\n",
    "        k += 1\n",
    "\n",
    "    return names[:n]\n",
    "\n",
    "def generate_random_fds(\n",
    "    n_vars: int,\n",
    "    num_fds: int | None = None,\n",
    "    max_lhs_size: int = 3,\n",
    "    max_rhs_size: int = 3,\n",
    "    allow_trivial: bool = False,\n",
    "    seed: int | None = None,\n",
    ") -> tuple[set[str], list[tuple[set[str], set[str]]]]:\n",
    "    \"\"\"\n",
    "    Generate random functional dependencies over n_vars attributes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_vars : number of attributes (>= 1)\n",
    "    num_fds : number of FDs to generate; default is a random integer in [n_vars, 2*n_vars]\n",
    "    max_lhs_size : maximum size of LHS for any FD (>=1)\n",
    "    max_rhs_size : maximum size of RHS for any FD (>=1)\n",
    "    allow_trivial : if False (default), ensure RHS has at least one attribute not in LHS\n",
    "    seed : optional random seed for reproducibility\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (attributes, fds)\n",
    "      attributes : set of attribute names (strings)\n",
    "      fds        : list of (set(lhs), set(rhs)) tuples\n",
    "    \"\"\"\n",
    "    if n_vars < 1:\n",
    "        raise ValueError(\"n_vars must be >= 1\")\n",
    "    if max_lhs_size < 1 or max_rhs_size < 1:\n",
    "        raise ValueError(\"max_lhs_size and max_rhs_size must be >= 1\")\n",
    "\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    attr_list = make_attribute_names(n_vars)\n",
    "    attributes = set(attr_list)\n",
    "\n",
    "    if num_fds is None:\n",
    "        num_fds = rng.randint(n_vars, 2 * n_vars)\n",
    "\n",
    "    fds = []\n",
    "    seen = set()  # for deduplication\n",
    "    attempts = 0\n",
    "    max_attempts = num_fds * 20  # generous cap to avoid infinite loops\n",
    "\n",
    "    while len(fds) < num_fds and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "\n",
    "        lhs_size = rng.randint(1, min(max_lhs_size, n_vars))\n",
    "        rhs_size = rng.randint(1, min(max_rhs_size, n_vars))\n",
    "\n",
    "        lhs = set(rng.sample(attr_list, lhs_size))\n",
    "\n",
    "        # Start with a random RHS\n",
    "        rhs = set(rng.sample(attr_list, rhs_size))\n",
    "\n",
    "        # Enforce non-triviality if requested: ensure RHS has something outside LHS\n",
    "        if not allow_trivial:\n",
    "            if rhs.issubset(lhs):\n",
    "                outside = list(attributes - lhs)\n",
    "                if not outside:\n",
    "                    # Can't make a non-trivial FD if all attributes are in LHS\n",
    "                    continue\n",
    "                # choose at least 1 attribute from outside lhs\n",
    "                k = rng.randint(1, min(rhs_size, len(outside)))\n",
    "                rhs = set(rng.sample(outside, k))\n",
    "            else:\n",
    "                # keep overlap but ensure at least one outside-LHS attribute exists\n",
    "                # (this keeps some partially overlapping FDs like {A} -> {A, B})\n",
    "                pass\n",
    "\n",
    "        # Disallow empty RHS (shouldn't happen with the above, but be safe)\n",
    "        if not rhs:\n",
    "            continue\n",
    "\n",
    "        # Normalize for deduplication\n",
    "        key = (tuple(sorted(lhs)), tuple(sorted(rhs)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(key)\n",
    "        fds.append((set(key[0]), set(key[1])))\n",
    "\n",
    "    return attributes, fds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: {'A', 'C', 'D', 'B'}\n",
      "FDs:\n",
      "{'C', 'D', 'B'} -> {'A'}\n",
      "{'C'} -> {'A', 'B'}\n",
      "{'C', 'D'} -> {'A', 'B'}\n",
      "{'A', 'C', 'D'} -> {'B'}\n",
      "{'C', 'D'} -> {'A', 'C', 'D'}\n"
     ]
    }
   ],
   "source": [
    "attributes, fds = generate_random_fds(\n",
    "    n_vars=4,\n",
    "    num_fds=5,\n",
    "    max_lhs_size=4,\n",
    "    max_rhs_size=3,\n",
    "    allow_trivial=False,\n",
    "    # seed=32,  # remove or change for different draws\n",
    ")\n",
    "\n",
    "print(\"Attributes:\", attributes)\n",
    "print(\"FDs:\")\n",
    "for lhs, rhs in fds:\n",
    "    print(f\"{lhs} -> {rhs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
