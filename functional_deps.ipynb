{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions (Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "import random\n",
    "\n",
    "def compute_closure(attributes, fds) -> set:\n",
    "    \"\"\"\n",
    "    Compute the closure of a set of attributes under a set of functional dependencies\n",
    "    ---------------------------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    closure = set(attributes)\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for fd in fds:\n",
    "            if fd[0].issubset(closure) and not fd[1].issubset(closure):\n",
    "                closure.update(fd[1])\n",
    "                changed = True\n",
    "    return closure\n",
    "\n",
    "def compute_all_closures(attributes, fds) -> dict:\n",
    "    \"\"\"\n",
    "    Compute the closure of all possible subsets of a set of attributes\n",
    "    ------------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    all_closures = {}\n",
    "    for r in range(1, len(attributes) + 1):\n",
    "        for subset in combinations(attributes, r):\n",
    "            subset_closure = compute_closure(set(subset), fds)\n",
    "            all_closures[tuple(subset)] = subset_closure\n",
    "    return all_closures\n",
    "\n",
    "def compute_candidate_keys(closure_set, attributes) -> list:\n",
    "    \"\"\"\n",
    "    Compute the candidate keys of a set of attributes\n",
    "    -------------------------------------------------\n",
    "    closure_set: a dictionary of all closures\n",
    "    attributes: a set of attributes\n",
    "    \"\"\"\n",
    "    super_keys = []\n",
    "    for i in closure_set:\n",
    "        if set(closure_set[i]) == set(attributes):\n",
    "            super_keys.append(i)\n",
    "    candidate_keys = []\n",
    "    for j in super_keys:\n",
    "        flag = False\n",
    "        for i in super_keys:\n",
    "            if set(i) != set(j):\n",
    "                if set(i).issubset(set(j)):\n",
    "                    flag = True\n",
    "        if flag == False:\n",
    "            candidate_keys.append(j)\n",
    "    return candidate_keys\n",
    "\n",
    "def find_prime_attributes(candidate_keys) -> set:\n",
    "    \"\"\"\n",
    "    Find the prime attributes of a set of candidate keys\n",
    "    ----------------------------------------------------\n",
    "    candidate_keys: a list of candidate keys\n",
    "    \"\"\"\n",
    "    prime_attributes = set()\n",
    "    for key in candidate_keys:\n",
    "        prime_attributes.update(key)\n",
    "    return prime_attributes\n",
    "\n",
    "def compute_single_covers(attributes, fds) -> dict:\n",
    "    \"\"\"\n",
    "    Compute the closure of each attribute in a set of attributes\n",
    "    ------------------------------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    all_closures = {}\n",
    "    for a in attributes:\n",
    "        subset_closure = compute_closure(a, fds)\n",
    "        all_closures[a] = subset_closure\n",
    "    return all_closures\n",
    "\n",
    "def project_dependency(fds, R_hat) -> list:\n",
    "    \"\"\"\n",
    "    Project a set of functional dependencies on a set of attributes\n",
    "    ---------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    R_hat: a set of attributes\n",
    "    \"\"\"\n",
    "    fds_hat = []\n",
    "    for fd in fds:\n",
    "        if fd[0].issubset(R_hat):\n",
    "            y = fd[1].intersection(R_hat)\n",
    "            if len(y)>0:\n",
    "                fds_hat.append((fd[0],y))\n",
    "    return fds_hat\n",
    "\n",
    "## Minimal cover computation\n",
    "\n",
    "def decompose_fds(fds) -> list:\n",
    "    \"\"\"Decompose each FD so that the RHS contains only one attribute.\n",
    "    For example, the FD {A} -> {B, C} will be decomposed into {A} -> {B} and {A} -> {C}.\n",
    "    ------------------------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    decomposed_fds = []\n",
    "    for lhs, rhs in fds:\n",
    "        for attr in rhs:\n",
    "            decomposed_fds.append((lhs, {attr}))\n",
    "    return decomposed_fds\n",
    "\n",
    "def remove_trivial_dependencies(fds) -> list:\n",
    "    \"\"\"Remove trivial FDs of the form A -> A.\n",
    "    -----------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    return [(lhs, rhs) for lhs, rhs in fds if lhs != rhs]\n",
    "\n",
    "def remove_redundant_dependencies(fds) -> list:\n",
    "    \"\"\"Remove redundant FDs by checking if we can infer a FD from others.\n",
    "    ---------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    non_redundant_fds = []\n",
    "    for i, (lhs, rhs) in enumerate(fds):\n",
    "        remaining_fds = fds[:i] + fds[i+1:]\n",
    "        closure_lhs = compute_closure(lhs, remaining_fds)\n",
    "        \n",
    "        if not rhs.issubset(closure_lhs):\n",
    "            non_redundant_fds.append((lhs, rhs))\n",
    "    \n",
    "    return non_redundant_fds\n",
    "\n",
    "def remove_redundant_dependencies(fds) -> list:\n",
    "    \"\"\"Remove redundant FDs by checking if we can infer a FD from others.\n",
    "    ---------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    len_fds_1 = len(fds)\n",
    "    len_fds_2 = 0\n",
    "    while len_fds_1>len_fds_2:\n",
    "        len_fds_1 = len(fds)\n",
    "        for i, (lhs, rhs) in enumerate(fds):\n",
    "            remaining_fds = fds[:i] + fds[i+1:]\n",
    "            closure_lhs = compute_closure(lhs, remaining_fds)\n",
    "            if rhs.issubset(closure_lhs):\n",
    "                fds.remove((lhs, rhs))\n",
    "        len_fds_2 = len(fds)\n",
    "    return fds\n",
    "\n",
    "def merge_fds(fds) -> list:\n",
    "    \"\"\"Merge FDs with the same LHS back together.\n",
    "    --------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    merged_fds = {}\n",
    "    for lhs, rhs in fds:\n",
    "        lhs = tuple(lhs)\n",
    "        if lhs in merged_fds:\n",
    "            merged_fds[lhs].update(rhs)\n",
    "        else:\n",
    "            merged_fds[lhs] = set(rhs)\n",
    "    \n",
    "    return [(set(lhs), rhs) for lhs, rhs in merged_fds.items()]\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"Generate all non-empty proper subsets of a set.\"\"\"\n",
    "    s = list(iterable)\n",
    "    combs = [[i for i in combinations(s, r)] for r in range(1, len(s)+1)]\n",
    "    return [x for xs in combs for x in xs]\n",
    "\n",
    "def remove_superfluous_lhs(fds, p):\n",
    "    \"\"\"\n",
    "    Simplify the LHS by checking if any proper subset of the LHS can imply the RHS.\n",
    "    --------------------------------------------------------------------------------\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    minimal_fds = []\n",
    "    for lhs, rhs in fds:\n",
    "        minimal_lhs = lhs\n",
    "        min_sub = 10000\n",
    "        minimals = []\n",
    "        for subset in powerset(lhs):\n",
    "            if len(subset) <= min_sub:\n",
    "                if rhs.issubset(compute_closure(set(subset), fds)):\n",
    "                    minimal_lhs = set(subset)\n",
    "                    min_sub = len(subset)\n",
    "                    minimals.append(minimal_lhs)\n",
    "        if len(minimals)>1 and random.randint(0, 10) < p*10:\n",
    "            minimal_lhs = set(random.choice(minimals))\n",
    "        else:\n",
    "            minimal_lhs = minimals[0]\n",
    "            \n",
    "        minimal_fds.append((minimal_lhs, rhs))\n",
    "    return minimal_fds\n",
    "\n",
    "def minimal_cover(fds, p = 0.5) -> list:\n",
    "    \"\"\"Find the minimal cover of a set of FDs.\n",
    "    -----------------------------------------\n",
    "    attributes: a set of attributes\n",
    "    fds: a list of functional dependencies (contains tuples of two sets. First set implies the second set)\n",
    "    \"\"\"\n",
    "    # Step 1: Decompose the RHS\n",
    "    decomposed_fds = decompose_fds(fds)\n",
    "\n",
    "    # Step 2: Simplify LHS\n",
    "    simplified_fds = remove_superfluous_lhs(decomposed_fds, p)\n",
    "\n",
    "    # Step 3: Remove trivial dependencies (A -> A)\n",
    "    simplified_fds = remove_trivial_dependencies(simplified_fds)\n",
    "\n",
    "    # Step 4: Remove redundant FDs\n",
    "    simplified_fds = remove_redundant_dependencies(simplified_fds)\n",
    "    \n",
    "    # Step 5: Recollect FDs with the same LHS\n",
    "    minimal_fds = merge_fds(simplified_fds)\n",
    "    \n",
    "    return minimal_fds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = {'A', 'B', 'C', 'D', 'E'}\n",
    "fds = [\n",
    "    ({'A'}, {'A', 'B', 'C'}),\n",
    "    ({'A', 'B'}, {'A'}),\n",
    "    ({'B', 'C'}, {'A', 'D'}),\n",
    "    ({'B'}, {'A', 'B'}),\n",
    "    ({'C'}, {'D'})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_closures = compute_all_closures(attributes, fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E'}+ = {'E'}\n",
      "{'C'}+ = {'C', 'D'}\n",
      "{'A'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'B'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'D'}+ = {'D'}\n",
      "{'E', 'C'}+ = {'E', 'C', 'D'}\n",
      "{'E', 'A'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'B'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'D'}+ = {'E', 'D'}\n",
      "{'A', 'C'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'B', 'C'}+ = {'A', 'B', 'C', 'D'}\n",
      "{'C', 'D'}+ = {'C', 'D'}\n",
      "{'A', 'B'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'A', 'D'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'B', 'D'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'E', 'A', 'C'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'B', 'C'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'C', 'D'}+ = {'E', 'C', 'D'}\n",
      "{'E', 'A', 'B'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'A', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'B', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'A', 'B', 'C'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'A', 'C', 'D'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'B', 'C', 'D'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'A', 'B', 'D'}+ = {'C', 'A', 'B', 'D'}\n",
      "{'E', 'A', 'B', 'C'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'A', 'C', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'B', 'C', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'E', 'A', 'B', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n",
      "{'A', 'B', 'C', 'D'}+ = {'A', 'B', 'C', 'D'}\n",
      "{'E', 'C', 'A', 'B', 'D'}+ = {'E', 'C', 'A', 'B', 'D'}\n"
     ]
    }
   ],
   "source": [
    "for k in all_closures:\n",
    "    print('{k}+ = {v}'.format(k=set(k), v=all_closures[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('E', 'A'), ('E', 'B')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_candidate_keys(all_closures, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'E'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_prime_attributes(compute_candidate_keys(all_closures, attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A'} -> {'B', 'C'}\n",
      "{'B'} -> {'A'}\n",
      "{'C'} -> {'D'}\n"
     ]
    }
   ],
   "source": [
    "minimal_fds = minimal_cover(fds, p = 0.4)\n",
    "for lhs, rhs in minimal_fds:\n",
    "    print(f\"{lhs} -> {rhs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency projection example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds = [\n",
    "    ({'A'}, {'A', 'B', 'C'}),\n",
    "    ({'A', 'B'}, {'A'}),\n",
    "    ({'B', 'C'}, {'A', 'D'}),\n",
    "    ({'B'}, {'A', 'B'}),\n",
    "    ({'C'}, {'D'})\n",
    "]\n",
    "\n",
    "R_hat = {'A', 'B'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'A'}, {'A', 'B'}), ({'A', 'B'}, {'A'}), ({'B'}, {'A', 'B'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dependency(fds, R_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
